{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddfb7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "is_cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a64cd17",
   "metadata": {},
   "source": [
    "# General setup and perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8e1fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate a wrapper.\n",
    "# model path is defaulted to our portable model:\n",
    "# https://huggingface.co/uw-hai/polyjuice\n",
    "# No need to change this unless you are using customized model\n",
    "from polyjuice import Polyjuice\n",
    "pj = Polyjuice(model_path=\"uw-hai/polyjuice\", is_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c007e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It is harmful for kids.',\n",
       " 'It is not that bad for kids.',\n",
       " \"It's great for kids.\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the base sentence\n",
    "text = \"It is great for kids.\"\n",
    "\n",
    "# perturb the sentence with one line:\n",
    "# When running it for the first time, the wrapper will automatically\n",
    "# load related models, e.g. the generator and the perplexity filter.\n",
    "perturbations = pj.perturb(text)\n",
    "perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0e3e5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It is great for kids but not for any adults.',\n",
       " 'It is not great for kids.',\n",
       " 'It is great for kids but not for anyone.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To perturb with more controls,\n",
    "\n",
    "perturbations = pj.perturb(\n",
    "    orig_sent=text,\n",
    "    # can specify where to put the blank. Otherwise, it's automatically selected.\n",
    "    # Can be a list or a single sentence.\n",
    "    blanked_sent=[\"It is [BLANK] for kids.\", \"It is great for [BLANK].\"],\n",
    "    # can also specify the ctrl code (a list or a single code.)\n",
    "    # The code should be from 'resemantic', 'restructure', 'negation', 'insert', 'lexical', 'shuffle', 'quantifier', 'delete'.\n",
    "    ctrl_code=\"negation\",\n",
    "    # Customzie perplexity score. \n",
    "    perplex_thred=20,\n",
    "    # number of perturbations to return\n",
    "    num_perturbations=3,\n",
    "    # the function also takes in additional arguments for huggingface generators.\n",
    "    num_beams=3\n",
    ")\n",
    "perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bac5621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negation'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detect the ctrl code from a given sentence pair\n",
    "pj.detect_ctrl_code(\"it's great for kids.\", 'It is great for kids but not for any adults.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bcc528",
   "metadata": {},
   "source": [
    "# Select for diversity\n",
    "\n",
    "Having each perturbation be represented by its token changes, control code, and dependency tree strcuture, we greedily select the ones that are least similar to those already selected. This tries to avoid redundancy in common perturbations such as black -> white.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "793f1239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It is great for kids.', 'It is terrible for kids.'),\n",
       " ('It is great for kids.', 'It is bad for kids.'),\n",
       " ('It is great for kids.', 'It is not for kids.'),\n",
       " ('It is great for kids.', 'It is good for kids too.'),\n",
       " ('It is great for kids.', 'It is good for kids.'),\n",
       " ('It is great for kids.', 'It is a great movie for kids.'),\n",
       " ('It is great for kids.', 'It is harmful for kids.'),\n",
       " ('It is great for kids.', 'is great for kids.'),\n",
       " ('It is great for kids.', 'It is bad for kids too.'),\n",
       " ('It is great for kids.', 'It is not great for kids.'),\n",
       " ('It is great for kids.', 'It is not good for kids.'),\n",
       " ('It is great for kids.', 'It is boring for kids.')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# over-generate some examples\n",
    "\n",
    "orig_text = \"It is great for kids.\"\n",
    "perturb_texts = pj.perturb(\n",
    "    orig_sent=orig_text, perplex_thred=10, num_perturbations=None, num_beams=3)\n",
    "orig_and_perturb_pairs = [(orig_text, perturb_text) for perturb_text in perturb_texts]\n",
    "orig_and_perturb_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "85693442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It is great for kids.', 'It is terrible for kids.'),\n",
       " ('It is great for kids.', 'is great for kids.'),\n",
       " ('It is great for kids.', 'It is not great for kids.')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled = pj.select_diverse_perturbations(\n",
    "    orig_and_perturb_pairs=orig_and_perturb_pairs, nsamples=3)\n",
    "sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca02b554",
   "metadata": {},
   "source": [
    "# Select surprising perturbations as counterfactual explanations\n",
    "\n",
    "Because different models/explainers may have different forms of predictions/feature weight computation methods, Polyjuice selection expects all predictions and feature weights to be precomputed. Here, we give an example of Quora Question Pair Detection. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "64272c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a perturbation base\n",
    "orig = (\n",
    "    \"How can I help a friend experiencing serious depression?\",\n",
    "    \"How do I help a friend who is in depression?\"\n",
    ")\n",
    "orig_label = 1\n",
    "\n",
    "# we perturb the second question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ca52692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a model\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "model_name = \"textattack/bert-base-uncased-QQP\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "# sentiment analysis is a general name in Huggingface to load the pipeline for text classification tasks.\n",
    "# set device=-1 if you don't have a gpu\n",
    "pipe = pipeline(\n",
    "    \"sentiment-analysis\", model=model, tokenizer=tokenizer, \n",
    "    framework=\"pt\", device=0 if is_cuda else -1, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "172c43d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'label': 0, 'score': 0.0179734043776989},\n",
       "  {'label': 1, 'score': 0.9820265769958496}],\n",
       " 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some wrapper for prediction\n",
    "import numpy as np\n",
    "def extract_predict_label(raw_pred):\n",
    "    raw_pred = sorted(raw_pred, key=lambda r: -r[\"score\"])\n",
    "    if raw_pred:\n",
    "        return raw_pred[0][\"label\"]\n",
    "    return None\n",
    "def predict(examples, predictor, batch_size=128):\n",
    "    raw_preds, preds, distribution = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for e in (range(0, len(examples), batch_size)):\n",
    "            raw_preds.extend(predictor(examples[e:e+batch_size]))\n",
    "    for raw_pred in raw_preds:\n",
    "        raw_pred = raw_pred if type(raw_pred) == list else [raw_pred]\n",
    "        for m in raw_pred:\n",
    "            m[\"label\"] = int(m[\"label\"].split(\"_\")[1])\n",
    "    return raw_preds\n",
    "\n",
    "p = predict([orig], predictor=pipe)[0]\n",
    "(p, extract_predict_label(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "893571aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How do I help a suicidal girl?',\n",
       " 'How do I help a friend who is suicidal?',\n",
       " 'How do I get help a friend who is in depression?',\n",
       " 'How do I help a friend who is in really bad health?',\n",
       " 'How do I help a friend who is in deep trouble?',\n",
       " 'How would I help a friend who is in depression?',\n",
       " 'How do I help a friend who is in health?',\n",
       " 'How do I help a friend?',\n",
       " 'How do I help a suicidal student?',\n",
       " 'How do I not help a friend who is in depression?',\n",
       " 'How can I help a friend who is in depression?']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## collect some base perturbations\n",
    "from polyjuice.generations import ALL_CTRL_CODES\n",
    "\n",
    "# perturb the second question in orig.\n",
    "perturb_idx = 1\n",
    "perturb_texts = pj.perturb(\n",
    "    orig[perturb_idx], \n",
    "    ctrl_code=ALL_CTRL_CODES, \n",
    "    num_perturbations=None, perplex_thred=10)\n",
    "\n",
    "perturb_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1ee1ab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Requirement already satisfied: shap in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (0.39.0)\n",
      "Requirement already satisfied: numpy in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from shap) (1.20.2)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from shap) (4.60.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: scikit-learn in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from shap) (0.24.2)\n",
      "Requirement already satisfied: pandas in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from shap) (1.2.4)\n",
      "Requirement already satisfied: scipy in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from shap) (1.6.3)\n",
      "Requirement already satisfied: numba in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from shap) (0.53.1)\n",
      "Requirement already satisfied: cloudpickle in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from shap) (1.6.0)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from numba->shap) (0.36.0)\n",
      "Requirement already satisfied: setuptools in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from numba->shap) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from pandas->shap) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from pandas->shap) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->shap) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from scikit-learn->shap) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/wtshuang/anaconda3/envs/polyjuice_env/lib/python3.7/site-packages (from scikit-learn->shap) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "# To estimate feature importance, we set up shap explainer\n",
    "# install shap\n",
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f71b6d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'How': 0.052321239694720134,\n",
       " 'do': 0.052321239694720134,\n",
       " 'I': 0.05254904864705168,\n",
       " 'help': 0.05254904864705168,\n",
       " 'a': 0.03752649684611242,\n",
       " 'friend': 0.03752649684611242,\n",
       " 'who': 0.03752649684611242,\n",
       " 'is': 0.03752649684611242,\n",
       " 'in': 0.2708918958087452,\n",
       " 'depression': 0.2708918958087452,\n",
       " '?': 0.07552210992434993}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shap\n",
    "import functools\n",
    "from copy import deepcopy\n",
    "# setup a prediction function for computing the shap feature importance\n",
    "\n",
    "def wrap_perturbed_instances(perturb_texts, orig, perturb_idx=1):\n",
    "    perturbs = []\n",
    "    for a in perturb_texts:\n",
    "        curr_example = deepcopy(list(orig))\n",
    "        curr_example[perturb_idx] = a\n",
    "        perturbs.append(tuple(curr_example))\n",
    "    return perturbs\n",
    "\n",
    "def predict_on_perturbs(perturb_texts, orig, predictor, perturb_idx=1):\n",
    "    perturbs = wrap_perturbed_instances(perturb_texts, orig, perturb_idx)\n",
    "    perturbs_preds = predict(perturbs, predictor=predictor)\n",
    "    perturbs_pred_dicts = [{p[\"label\"]: p[\"score\"] for p in perturbs_pred} for perturbs_pred in perturbs_preds]\n",
    "    orig_preds = predict([orig], predictor=predictor)\n",
    "    orig_pred = extract_predict_label(orig_preds[0])\n",
    "    # the return is probability of the originally predicted label\n",
    "    return [pr_dict[orig_pred] for pr_dict in perturbs_pred_dicts]\n",
    "def normalize_shap_importance(features, importances, is_use_abs=True):\n",
    "    normalized_features = {}\n",
    "    for idx, (f, v) in enumerate(zip(features, importances)):\n",
    "        f = f.strip('Ä ')\n",
    "        if not f.startswith(\"##\"): \n",
    "            key, val = \"\", 0\n",
    "        key += f.replace(\"#\", \"\").strip()\n",
    "        val += v\n",
    "        if (idx == len(features)-1 or (not features[idx+1].startswith(\"##\"))) and key != \"\":\n",
    "            normalized_features[key] = abs(val) if is_use_abs else val\n",
    "    return normalized_features\n",
    "def explain_with_shap(orig, predictor=pipe, tokenzier=pipe.tokenizer, perturb_idx=1):\n",
    "    predict_for_shap_func = functools.partial(\n",
    "        predict_on_perturbs, orig=orig, predictor=predictor, perturb_idx=perturb_idx)\n",
    "    shap_explainer = shap.Explainer(predict_for_shap_func, tokenizer) \n",
    "    exp = shap_explainer([str(orig[perturb_idx])])\n",
    "    return normalize_shap_importance(exp.data[0], exp.values[0])\n",
    "\n",
    "feature_importance_dict = explain_with_shap(orig)\n",
    "feature_importance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "569debb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Munch({'case': 'Suprise flip', 'pred': 0, 'changed_features': ['help'], 'perturb_text': 'How do I not help a friend who is in depression?'}),\n",
       " Munch({'case': 'Suprise unflip', 'pred': 1, 'changed_features': ['depression'], 'perturb_text': 'How do I help a friend who is in really bad health?'})]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the predictions for original and also new instances\n",
    "orig_pred = predict([orig], predictor=pipe)[0]\n",
    "\n",
    "perturb_instances = wrap_perturbed_instances(perturb_texts, orig, perturb_idx)\n",
    "perturb_preds = predict(perturb_instances, predictor=pipe)\n",
    "\n",
    "surprises = pj.select_surprise_explanations(\n",
    "    orig_text=orig[perturb_idx], \n",
    "    perturb_texts=perturb_texts, \n",
    "    orig_pred=orig_pred, \n",
    "    perturb_preds=perturb_preds, \n",
    "    feature_importance_dict=feature_importance_dict)\n",
    "surprises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3215f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
